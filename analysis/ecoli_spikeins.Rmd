---
title: "E coli spike-in experiments"
output:
  workflowr::wflow_html:
      code_folding: hide
---

# E coli spike-in experiment results

E coli K12 strain was spiked into E coli BL21 with different proportions:

| Lib Name     | Spike in %           | \~Cell equivalent\* |
|--------------|----------------------|----------------------|
| 0-K12Rep1    | 0%K12Rep1(BL2 only)  | 318                  |
| 0-K12Rep2    | 0%K12Rep2 (BL2 only) | 202                  |
| 1-K12Rep1    | 1%K12Rep1            | 601                  |
| 1-K12Rep2    | 1%K12Rep2            | 585                  |
| 10-K12Rep1   | 10%K12Rep1           | 86                   |
| 10-K12Rep2   | 10%K12Rep2           | 74                   |
| 1_10-K12Rep1 | 0.1%K12Rep1          | 11,139               |
| 5-K12Rep1    | 5%K12Rep1            | 188                  |
| 5-K12Rep2    | 5%K12Rep2            | 228                  |

\*based on R1 unique read number.

The 1_10-K12Rep1 sample is currently omitted in this analysis as it is too large to process with the existing script.

## MultiQC reports:

-   [AGRF_CAGRF220410419_HFVGHDSX3 MultiQC pre-duplex](AGRF_CAGRF220410419_HFVGHDSX3_multiqc/multiqc_report.html)
-   [AGRF_CAGRF220410419_HFVGHDSX3 MultiQC duplex](AGRF_CAGRF220410419_HFVGHDSX3_multiqc/multiqc_report_consensus.html)

```{r setup, include=FALSE}
DOCNAME = "Analyse E. coli spike-ins"
knitr::opts_chunk$set(autodep        = TRUE,
                      cache          = FALSE,
                      cache.path     = paste0("cache/", DOCNAME, "/"),
                      cache.comments = FALSE,
                      cache.lazy     = FALSE,
                      echo           = TRUE,
                      error          = FALSE,
                      fig.align      = "center",
                      fig.width      = 7,
                      fig.height     = 5,
                      dev            = c("png"),
                      message        = FALSE,
                      warning        = FALSE)
```


```{r libraries, cache=FALSE, message=FALSE}
library(ggplot2)
library(data.table)
library(dplyr)
library(here)
library(tibble)
library(stringr)
library(Rsamtools)
library(GenomicRanges)
library(seqinr)
library(parallel)
library(readxl)
library(patchwork)
library(RColorBrewer)
library(UpSetR)
library(vcfR)
library(tidyr)
library('R.utils')
```

```{r source}
source(here('code/load_data.R'))
source(here('code/plot.R'))
source(here('code/efficiency_nanoseq_functions.R'))
```

```{r variables}
genome_max <- 4528118
cores <- 8
```

```{r paths}
genomeFile <- here('data/ref/Escherichia_coli_strain_BL21_TaKaRa.fasta')
rinfo_dir <- here('data/ecoli/AGRF_CAGRF220410419_HFVGHDSX3/QC/read_info')
markdup_dir <- here('data/ecoli/AGRF_CAGRF220410419_HFVGHDSX3/QC/mark_duplicates')
qualimap_dir <- here('data/ecoli/AGRF_CAGRF220410419_HFVGHDSX3/QC/qualimap')
qualimap_cons_dir <- here('data/ecoli/AGRF_CAGRF220410419_HFVGHDSX3/QC/consensus/qualimap')
variant_dir <- here('data/ecoli/AGRF_CAGRF220410419_HFVGHDSX3/variants')
variant_nvc_dir <- here('data/ecoli/AGRF_CAGRF220410419_HFVGHDSX3/variants_nvc')
nucdiff_snp_file <- here('data/ref/nucdiff/ecoli_BL21_vs_ATCC_1.snps')
```

```{r calculate_metrics}
sample_names <- list.files(rinfo_dir) %>%
                str_split('\\.txt.gz') %>%
                lapply(., dplyr::first) %>%
                unlist() %>%
                str_split('_') %>%
                lapply(., head, 2) %>%
                lapply(., paste, collapse='-') %>%
                unlist()

# load variant data
var_sample_names <- list.files(variant_dir) %>%
                str_split('_HFVGHDSX3') %>%
                lapply(., dplyr::first) %>%
                unlist()

# load reference SNPs
ref_snps <- read.delim(nucdiff_snp_file, sep = '\t', header = FALSE)
N_TOTAL_VARS <- length(unique(ref_snps$V1))

vaf_vs <- load_variants(variant_dir, var_sample_names) %>%
            calculate_vafs() %>%
            mutate(is_ref_snp = POS %in% ref_snps$V1)

var_nvc <- load_variants(variant_nvc_dir, sample_names) %>%
            mutate(VAF = INFO %>%
                       strsplit("AF=") %>%
                       lapply(., last) %>%
                       unlist() %>%
                       strsplit(",") %>%
                       lapply(., last) %>%
                       unlist() %>%
                       as.numeric(),
                   is_ref_snp = POS %in% ref_snps$V1) %>%
            filter(ALT %in% c('A', 'T', 'G', 'C'))

# load and fetch duplicate rate from MarkDuplicates output
mdup <- load_markdup_data(markdup_dir, sample_names)

# get mean coverage for pre and post-consensus reads
qmap_cov <- get_qmap_coverage(qualimap_dir, sample_names)
qmap_cons_cov <- get_qmap_coverage(qualimap_cons_dir, sample_names)

# uncomment below to calculate metrics
# calculate metrics for nanoseq
rlen <- 151; skips <- 5
# metrics <- calc_metrics_new_rbs(rinfo_dir, cores = cores) %>% bind_rows()
metrics <- readRDS(here('data/metrics_spikeins.rds'))
metrics$single_family_fraction <- metrics$single_families / metrics$total_families

metrics$duplicate_rate <- mdup
metrics$duplex_coverage_ratio <- qmap_cov$coverage / qmap_cons_cov$coverage
metrics$duplex_coverage_ratio[qmap_cons_cov$coverage < 1] <- 0 # fix when < 1 duplex cov
metrics$sample <- gsub('-HFVGHDSX3', '', sample_names)

# cache metrics object
# saveRDS(metrics, file = here('data/metrics.rds'))

# prepare for plotting
mm <- data.frame(reshape2::melt(metrics))
colnames(mm)[2] <- 'metric'
```

```{r plot_by_sample, fig.width=16, fig.height=10}
ggplot(mm, aes(sample, value)) + 
    geom_point() +
    theme_bw() +
    theme(axis.text.x = element_text(angle = 90)) +
    facet_wrap(~metric, scales = 'free') +
    scale_colour_brewer(palette = 'Dark2')
```

## Metric comparison plots

### Duplicate rate

Fraction of duplicate reads calculated by [Picard's MarkDuplicates](https://gatk.broadinstitute.org/hc/en-us/articles/360037052812-MarkDuplicates-Picard-). This is based on barcode-aware aligned duplicates mapping to the same 5' positions for both read pairs. The [NanoSeq Analysis pipeline](https://github.com/cancerit/NanoSeq) states the optimal empirical duplicate rate is 75-76% (marked in the plot).

```{r duplicate_rate}
metric <- 'duplicate_rate'
ggplot(mm[mm$metric == metric,], aes(sample, value)) +
        geom_histogram(stat = 'identity', position = 'dodge') +
        theme_bw() +
        coord_flip() +
        geom_hline(yintercept = c(0.75, 0.76), alpha = 0.4)  +
        ggtitle(metric)
```

### Fraction of singleton reads

Shows the number of single-read families divided by the total number of reads. As suggested by [Stoler et al. 2016](https://doi.org/10.1186/s13059-016-1039-4), this metric can server as a proxy for error rate, as (uncorrected) barcode mismatches will manifest as single-read families. The lower the fraction of singletons, the better.

```{r singletons}
metric <- 'frac_singletons'
ggplot(mm[mm$metric == metric,], aes(sample, value)) +
        geom_histogram(stat = 'identity', position = 'dodge') +
        theme_bw() +
        coord_flip() +
        ggtitle(metric)
```

### Drop-out rate

This is the same calculation as F-EFF in the [NanoSeq Analysis pipeline](https://github.com/cancerit/NanoSeq):

"This shows the fraction of read bundles missing one of the two original strands beyond what would be expected under random sampling (assuming a binomial process). Good values are between 0.10-0.30, and larger values are likely due to DNA damage such as modified bases or internal nicks that prevent amplification of one of the two strands. Larger values do not impact the quality of the results, just reduce the efficiency of the protocol."

This is similar to the singleton fraction, but taking into account loss of pairs due to sampling. The optimal range is shown by the lines.

```{r drop_out_rate}
metric <- 'drop_out_rate'
ggplot(mm[mm$metric == metric,], aes(sample, value)) +
        geom_histogram(stat = 'identity', position = 'dodge') +
        theme_bw() +
        coord_flip() +
        geom_hline(yintercept = c(0.1, 0.3), alpha = 0.4)  +
        ggtitle(metric)
```

### Efficiency

Efficiency is the number of duplex bases divided by the number of sequenced bases. According the [NanoSeq Analysis pipeline](https://github.com/cancerit/NanoSeq), this value is maximised at \~0.07 when duplicate rates and strand drop-outs are optimal.

```{r efficiency}
metric <- 'efficiency'
ggplot(mm[mm$metric == metric,], aes(sample, value)) +
        geom_histogram(stat = 'identity', position = 'dodge') +
        theme_bw() +
        coord_flip() +
        geom_hline(yintercept = c(0.07), alpha = 0.4)  +
        ggtitle(metric)
```

### GC deviation

GC deviation is the absolute difference between `GC_BOTH` and `GC_SINGLE` calculated by the [NanoSeq Analysis pipeline](https://github.com/cancerit/NanoSeq). The lower this deviation, the better.

"GC_BOTH and GC_SINGLE: the GC content of RBs with both strands and with just one strand. The two values should be similar between them and similar to the genome average. If there are large deviations that is possibly due to biases during PCR amplification. If GC_BOTH is substantially larger than GC_SINGLE, DNA denaturation before dilution may have taken place."

```{r gc_deviation}
metric <- 'gc_deviation'
ggplot(mm[mm$metric == metric,], aes(sample, value)) +
        geom_histogram(stat = 'identity', position = 'dodge') +
        theme_bw() +
        coord_flip() +
        ggtitle(metric)
```

### Duplex Coverage ratio

The mean sequence (pre-duplex) coverage divided by mean duplex coverage. Indicates the yield of how much duplex coverage we get at each sample's sequence coverage. [Abascal et al.](https://doi.org/10.1038/s41586-021-03477-4) report that their yield was approximately 30x (marked on the plot).

```{r duplex_coverage_ratio}
metric <- 'duplex_coverage_ratio'
ggplot(mm[mm$metric == metric,], aes(sample, value)) +
        geom_histogram(stat = 'identity', position = 'dodge') +
        theme_bw() +
        coord_flip() +
        geom_hline(yintercept = 30, alpha = 0.4)  +
        ggtitle(metric)
```

## Family statistics

Comparison of family pair sizes between samples (these are calculated from total reads of paired AB and BA families).

```{r family_sizes, fig.width = 8, fig.height = 5}
ggplot(mm[mm$metric %like% 'family', ], aes(value, sample, colour = metric)) +
        geom_point() +
        coord_trans(x='log2') +
        scale_x_continuous(breaks=seq(0, 94, 8)) +
        theme(axis.text.x = element_text(size=5)) +
        theme_bw() +
        ggtitle('Family pair sizes')
```

The following plot shows:

-   families_gt1: number of family pairs where at least one family (AB or BA) has \> 1 reads.
-   paired_families: number of family pairs where both families (AB and BA) have \> 0 reads.
-   paired_and_gt1: number of family pairs where both families (AB and BA) have \> 1 reads.

```{r family_stats, fig.width = 14, fig.height = 5}
p1 <- ggplot(mm[mm$metric %like% 'pair|gt1', ], aes(value, sample, fill = metric)) +
        geom_bar(stat='identity', position='dodge') +
        theme_bw() +
        ggtitle('Family statistics')
p2 <- ggplot(mm[mm$metric %like% 'pair|gt1' & !mm$sample %like% '1-10', ], aes(value, sample, fill = metric)) +
        geom_bar(stat='identity', position='dodge') +
        theme_bw() +
        ggtitle('Family statistics without 0.1% spike-in sample')
p1 + p2
```
## Variant calling analysis

Here we show the VAF mean, number of variants called, as well as a number of other metrics used in estimating number of variants called.

```{r variant_calling}
# number of differing variant sites between the E coli genomes
COVERAGE_PER_GENOME <- 10

vaf_sm <- data.table(vaf_vs)[, list(VAF_mean = mean(VAF), nvars_ref = sum(is_ref_snp), nvars_nonref = sum(!is_ref_snp)), by=sample] %>%
            mutate(VAF_mix = as.character(sample) %>% strsplit('-K12Rep') %>%
                       lapply(dplyr::first) %>% unlist()) %>%
            left_join(., select(metrics, c(sample, efficiency)), by='sample') %>%
            separate(col = sample, sep = 'Rep', into = c('sample', 'replicate')) %>%
            mutate(coverage = qmap_cons_cov$coverage,
                   cells = c(318, 202, 11139, 601, 585, 86, 74, 188, 228)) %>%
            reshape2::melt(., id.vars = c("sample", "replicate", "cells","VAF_mean",
                                          "VAF_mix", "efficiency", "coverage"),
                 measure.vars = c("nvars_ref", "nvars_nonref"),
                 variable.name = "nvars_type", value.name = "nvars_count")
    
vaf_sm$VAF_mix[vaf_sm$VAF_mix == '1-10'] <- 0.1
# vaf_sm$efficiency[vaf_sm$sample == ] <- 0.002 # a guess
# vaf_sm$cells <- c(318, 202, 11139, 601, 585, 86, 74, 188, 228)
vaf_sm$VAF_mix <- as.numeric(vaf_sm$VAF_mix) / 100
vaf_sm$expected_coverage <- vaf_sm$cells * COVERAGE_PER_GENOME * vaf_sm$efficiency
vaf_sm$variant_caller <- 'varscan2'

print(vaf_sm)

vaf_nvc <- data.table(var_nvc)[, list(VAF_mean = mean(VAF), nvars_ref = sum(is_ref_snp),
                                 nvars_nonref = sum(!is_ref_snp)), by=sample] %>%
            mutate(VAF_mix = as.character(sample) %>% strsplit('-K12Rep') %>%
                       lapply(dplyr::first) %>%
                       unlist(),
                   sample = gsub('-HFVGHDSX3', '', sample)) %>%
            left_join(., select(metrics, c(sample, efficiency)), by='sample') %>%
            separate(col = sample, sep = 'Rep', into = c('sample', 'replicate')) %>%
            mutate(coverage = qmap_cons_cov$coverage,
                   cells = c(318, 202, 11139, 601, 585, 86, 74, 188, 228)) %>%
            reshape2::melt(.,
                           id.vars = c("sample", "replicate", "cells", "VAF_mean",
                                       "VAF_mix", "efficiency", "coverage"),
                 measure.vars = c("nvars_ref", "nvars_nonref"),
                 variable.name = "nvars_type", value.name = "nvars_count") %>%
            mutate(variant_caller = 'nvc')
print(vaf_nvc)
```

### Compare variants to expected reference vars

Plot number of variants that match the expected reference SNPs versus the non-reference SNPs.

```{r variant_calls_matching_ref, fig.width=16.5, fig.height=6}
p1 <- ggplot(vaf_sm, aes(sample, nvars_count, colour = nvars_type, shape = nvars_type)) +
    geom_point(size = 3) +
    theme_minimal() +
    theme(legend.position = 'bottom') +
    ggtitle('Varscan reference and non-reference variants called')
p2 <- ggplot(vaf_sm[vaf_sm$nvars_type == 'nvars_ref',], aes(sample, nvars_count / N_TOTAL_VARS)) +
    geom_point(size = 3) +
    theme_minimal() +
    theme(legend.position = 'bottom') +
    ylim(0, 1) +
    ggtitle('Varscan fraction of reference variants called')
p3 <- ggplot(vaf_sm, aes(sample, coverage, colour = replicate, shape = replicate)) +
    geom_point(size = 3) +
    theme_minimal() +
    theme(legend.position = 'bottom') +
    ggtitle('Duplex coverage')

p4 <- ggplot(vaf_nvc, aes(sample, nvars_count, colour = nvars_type, shape = nvars_type)) +
    geom_point(size = 3) +
    theme_minimal() +
    theme(legend.position = 'bottom') +
    ggtitle('NVC reference and non-reference variants called')
p5 <- ggplot(vaf_nvc[vaf_nvc$nvars_type == 'nvars_ref',], aes(sample, nvars_count / N_TOTAL_VARS)) +
    geom_point(size = 3) +
    theme_minimal() +
    theme(legend.position = 'bottom') +
    ylim(0, 1) +
    ggtitle('NVC fraction of reference variants called')
p6 <- ggplot(vaf_nvc, aes(sample, coverage, colour = replicate, shape = replicate)) +
    geom_point(size = 3) +
    theme_minimal() +
    theme(legend.position = 'bottom') +
    ggtitle('Duplex coverage')

p1 + p2 + p3
p4 + p5 + p6
```

#### Varscan vs. Naive Variant Caller

Compare number of variants called.

```{r varscan_vs_nvc, fig.width = 6.5, fig.height = 5}
select_cols <- c('sample', 'replicate', 'nvars_type', 'nvars_count')
varc <- vaf_sm[,select_cols] %>%
        inner_join(., vaf_nvc[,select_cols], by = c('sample', 'replicate', 'nvars_type')) %>%
        rename(c('nvars_count.x' = 'varscan',
                 'nvars_count.y' = 'nvc'))
ggplot(varc, aes(varscan, nvc, shape = sample, colour = nvars_type)) +
    geom_point(size = 3) +
    theme_minimal() +
    ylim(0, 12000) +
    xlim(0, 12000) +
    ggtitle('Varscan vs. NVC number of variants called')
```


### Expected coverage

Here we plot the observed mean coverage versus the expected coverage, the latter is calculated as $n * c * d$ where $n =$ number of input cells, $c =$ target coverage per genome equivalent (10) and $d =$ duplex efficiency.

We can see that the real coverage is higher than expected, this is likely due to the efficiency calculation being based on 2 minimum reads per strand, whereas we ran duplex consensus calling without SSC.

```{r expected_coverage, fig.width = 6, fig.height = 5}
ggplot(vaf_sm, aes(expected_coverage, coverage, shape=sample)) +
    geom_point() +
    theme_minimal() +
    geom_abline(slope = 1)
```

### Expected variants

Here we use the revised model to estimate the number of variants we expected to call with 95\% confidence, using the formula above.

```{r expected_variants, fig.width=12, fig.height=5}
vaf_sm$expected_variants <- (1 - (1 - vaf_sm$VAF_mix) ^ round(vaf_sm$expected_coverage)) * N_TOTAL_VARS
vaf_sm$expected_variants_cov <- (1 - (1 - vaf_sm$VAF_mix) ^ round(vaf_sm$coverage)) * N_TOTAL_VARS

p1 <- ggplot(vaf_sm[vaf_sm$nvars_type == 'nvars_ref',], aes(expected_variants, nvars_count, shape=sample)) +
    geom_point() +
    theme_minimal() +
    geom_abline(slope = 1) +
    scale_x_continuous(limits = c(0,15000)) +
    scale_y_continuous(limits = c(0,15000)) +
    ggtitle('Expected vs. actual variants, based on expected coverage')

p2 <- ggplot(vaf_sm[vaf_sm$nvars_type == 'nvars_ref',], aes(expected_variants_cov, nvars_count, shape=sample)) +
    geom_point() +
    theme_minimal() +
    geom_abline(slope = 1) +
    scale_x_continuous(limits = c(0,15000)) +
    scale_y_continuous(limits = c(0,15000)) +
    ggtitle('Expected vs. actual variants, based on actual coverage')

p1 + p2
```

```{r presentation_expected_variants, fig.width=15, fig.height=5, eval=FALSE}
p1 <- ggplot(vaf_sm[vaf_sm$nvars_type == 'nvars_ref',], aes(expected_coverage, coverage, shape=sample)) +
    geom_point() +
    theme_minimal() +
    geom_abline(slope = 1) +
    theme(legend.position = 'none') +
    ggtitle('Expected vs. actual coverage')

p2 <- ggplot(vaf_sm[vaf_sm$nvars_type == 'nvars_ref',], aes(expected_variants, nvars_count, shape=sample)) +
    geom_point() +
    theme_minimal() +
    geom_abline(slope = 1) +
    theme(legend.position = 'none') +
    scale_x_continuous(limits = c(0,15000)) +
    scale_y_continuous(limits = c(0,15000)) +
    ggtitle('Expected vs. actual variants\nbased on expected coverage')

p3 <- ggplot(vaf_sm[vaf_sm$nvars_type == 'nvars_ref',], aes(expected_variants_cov, nvars_count, shape=sample)) +
    geom_point() +
    theme_minimal() +
    geom_abline(slope = 1) +
    theme(legend.position = 'none') +
    scale_x_continuous(limits = c(0,15000)) +
    scale_y_continuous(limits = c(0,15000)) +
    ggtitle('Expected vs. actual variants\nbased on actual coverage')

p1 + p2 + p3
```

```{r poster_plots, fig.width=8, fig.height=3, include=FALSE, eval=FALSE}
pdf('coverage.pdf', width = 4, height = 3)
vaf_sm$VAF_mix <- factor(vaf_sm$VAF_mix)
ggplot(vaf_sm[vaf_sm$nvars_type == 'nvars_ref',], aes(expected_variants_cov, nvars_count, shape=VAF_mix, colour=VAF_mix)) +
    geom_point() +
    theme_bw() +
    geom_abline(slope = 1) +
    theme(legend.position = 'right') +
    scale_x_continuous(limits = c(0,15000)) +
    scale_y_continuous(limits = c(0,15000)) +
    ggtitle('Expected vs. actual variants') +
    xlab('Expected variants') +
    ylab('Actual variants') +
    scale_color_brewer(palette = 'Dark2')
dev.off()
```




### Expected raw coverage (re-estimated)

Here it looks like we can't estimate raw coverage very well, so I'm just going to use actual coverage in the meantime, for downstream analyses.

```{r exp_raw_coverage, fig.width=11, fig.height=4}
eff <- vaf_sm[vaf_sm$nvars_type == 'nvars_ref',] %>% rename(., c('coverage' = 'dup_coverage'))
eff$sample <- paste0(eff$sample, 'Rep', eff$replicate)
eff$raw_coverage <- qmap_cov$coverage
md <- list.files(
        markdup_dir,
        full.names = TRUE,
        recursive = TRUE,
        pattern = 'txt') %>%
        paste('grep -E "Library|LIBRARY"', .) %>%
        lapply(., fread) %>%
        suppressMessages()

# calculate sequencing ratio
eff$libsize <- lapply(md, select, ESTIMATED_LIBRARY_SIZE) %>% unlist() %>% as.numeric() 
eff$total_reads <- lapply(md, function(x){x$READ_PAIRS_EXAMINED - x$READ_PAIR_OPTICAL_DUPLICATES}) %>% as.numeric()
eff$seqratio <- eff$total_reads / eff$libsize

# estimate duplex coverage from seqratio
eff$est_raw_coverage <- eff$seqratio * eff$cells
eff$est_efficiency <- (ppois(q=2-0.1, lambda=eff$seqratio/2, lower.tail=F)/(1-dpois(0, eff$seqratio/2)))^2 / (eff$seqratio/(1-exp(-eff$seqratio)))

# here we add drop-out rate to the mix
eff <- filter(mm, metric == 'drop_out_rate') %>%
        select(c('sample', 'value')) %>%
        rename(value = 'drop_out_rate') %>%
        left_join(eff, ., by = 'sample')
eff$est_efficiency_wdo <- eff$est_efficiency * (1 - eff$drop_out_rate)
eff$est_dup_coverage <- eff$raw_coverage * eff$est_efficiency
eff$expected_variants <- (1 - (1 - eff$VAF_mix) ^ round(eff$est_dup_coverage)) * N_TOTAL_VARS

p1 <- ggplot(eff, aes(raw_coverage, est_raw_coverage, colour=factor(VAF_mix), shape=factor(VAF_mix))) +
    geom_point() +
    theme_minimal() +
    geom_abline(slope = 1) +
    xlab('Raw coverage') +
    ylab('Estimated raw coverage') +
    ggtitle('Estimated vs. actual raw coverage') +
    scale_colour_brewer(palette = 'Dark2')

p2 <- ggplot(eff, aes(raw_coverage, est_raw_coverage, colour=factor(VAF_mix), shape=factor(VAF_mix))) +
    geom_point() +
    theme_minimal() +
    geom_abline(slope = 1) +
    xlab('Raw coverage') +
    ylab('Estimated raw coverage') +
    ggtitle('Estimated vs. actual raw coverage (zoom)') +
    scale_colour_brewer(palette = 'Dark2') +
    xlim(0, 50000) + ylim(0, 45000)

p1 + p2
```

### Expected efficiency

Ideally, we want to try to estimate the coverage prior to sequencing. In these experiments, our drop-out rate was much higher than expected, so we will have to integrate that into the estimate. Here we estimate the efficiency and ultimately the number of variants knowing only the drop-out rate and library size.

```{r exp_efficiency, fig.width=11, fig.height=4}
p1 <- ggplot(eff, aes(efficiency, est_efficiency, colour=factor(VAF_mix), shape=factor(VAF_mix))) +
    geom_point() +
    theme_minimal() +
    geom_abline(slope = 1) +
    xlab('Efficiency') +
    ylab('Estimated duplex efficiency') +
    ggtitle('Estimated vs. actual duplex efficiency') +
    scale_colour_brewer(palette = 'Dark2') +
    xlim(0, 0.05) + ylim(0, 0.05)

p2 <- ggplot(eff, aes(efficiency, est_efficiency_wdo, colour=factor(VAF_mix), shape=factor(VAF_mix))) +
    geom_point() +
    theme_minimal() +
    geom_abline(slope = 1) +
    xlab('Efficiency') +
    ylab('Estimated duplex efficiency with drop-out') +
    ggtitle('Estimated vs. actual duplex efficiency (with drop-out)') +
    scale_colour_brewer(palette = 'Dark2') +
    xlim(0, 0.02) + ylim(0, 0.02)

p1 + p2
```


### Expected duplex coverage adjusted by drop-out

```{r exp_dup_coverage, fig.width=16.5, fig.height=4}
p5 <- ggplot(eff, aes(dup_coverage, est_dup_coverage, colour=factor(VAF_mix), shape=factor(VAF_mix))) +
    geom_point() +
    theme_minimal() +
    geom_abline(slope = 1) +
    ylab('Estimated duplex coverage') +
    xlab('Duplex coverage') +
    ggtitle('Estimated vs. actual duplex\ncoverage') +
    scale_colour_brewer(palette = 'Dark2') +
    xlim(0, 500) + ylim(0, 500)

p6 <- ggplot(eff, aes(dup_coverage, est_dup_coverage * (1 - drop_out_rate), colour=factor(VAF_mix), shape=factor(VAF_mix))) +
    geom_point() +
    theme_minimal() +
    geom_abline(slope = 1) +
    ylab('Estimated duplex coverage') +
    xlab('Duplex coverage') +
    ggtitle('Estimated vs. actual duplex\ncoverage (zoom) w/ drop out') +
    scale_colour_brewer(palette = 'Dark2') +
    xlim(0, 50) + ylim(0, 50)

p7 <- ggplot(eff, aes(dup_coverage, est_dup_coverage * (1 - drop_out_rate) * 0.5, colour=factor(VAF_mix), shape=factor(VAF_mix))) +
    geom_point() +
    theme_minimal() +
    geom_abline(slope = 1) +
    ylab('Estimated duplex coverage') +
    xlab('Duplex coverage') +
    ggtitle('Estimated vs. actual duplex\ncoverage (zoom) w/ drop out + correction') +
    scale_colour_brewer(palette = 'Dark2') +
    xlim(0, 50) + ylim(0, 50)

p5 + p6 + p7
```

### Expected variants recalculated with expected efficiency

```{r expected_variants_recalc, fig.width=12, fig.height=4.5}
eff$expected_variants <- (1 - (1 - eff$VAF_mix) ^ round(eff$est_dup_coverage * (1 - eff$drop_out_rate) * 0.5)) * N_TOTAL_VARS
eff$expected_variants_cov <- (1 - (1 - eff$VAF_mix) ^ round(eff$dup_coverage)) * N_TOTAL_VARS

p1 <- ggplot(eff, aes(nvars_count, expected_variants, shape=factor(VAF_mix))) +
    geom_point() +
    theme_minimal() +
    geom_abline(slope = 1) +
    scale_x_continuous(limits = c(0,15000)) +
    scale_y_continuous(limits = c(0,15000)) +
    ggtitle('Expected vs. actual variants, based on expected coverage')

p2 <- ggplot(eff, aes(nvars_count, expected_variants_cov, shape=factor(VAF_mix))) +
    geom_point() +
    theme_minimal() +
    geom_abline(slope = 1) +
    scale_x_continuous(limits = c(0,15000)) +
    scale_y_continuous(limits = c(0,15000)) +
    ggtitle('Expected vs. actual variants, based on actual coverage')

p1 + p2
```
